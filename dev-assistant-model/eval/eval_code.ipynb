{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:37<00:00, 12.34s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "model_path = '/home/uework/AiWeb/pwz/github/model/Nous-Hermes-Llama2-13b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,torch_dtype='auto',quantization_config=quantization_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "    json.ipynb\n",
      "    lua.ipynb\n",
      "    utils.py\n",
      "    dialogue.ipynb\n",
      "    requirements.txt\n",
      "    README.md\n",
      "    scripts/\n",
      "        arguments.py\n",
      "        bpe_training.py\n",
      "        codeparrot_training.py\n",
      "        human_eval.py\n",
      "        initialize_model.py\n",
      "        minhash_deduplication.py\n",
      "        preprocessing.py\n",
      "        pretokenizing.py\n",
      "        validation_loss.py\n",
      "        preprocess.sh\n",
      "        tests/\n",
      "            test_deduplicate.py\n",
      "            __init__.py\n",
      "        __pycache__/\n",
      "            arguments.cpython-310.pyc\n",
      "            minhash_deduplication.cpython-310.pyc\n",
      "            preprocessing.cpython-310.pyc\n",
      "    __pycache__/\n",
      "        utils.cpython-310.pyc\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "\n",
    "print(list_files('/home/uework/AiWeb/pwz/github/luacoder/data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 03:59:41.346131: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 03:59:42.003505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "I have a cat named Snoop. She's so adorable and fluffy that I just had to share her with the world.</s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message = \"Hello, my dog is cute\"\n",
    "input_ids = tokenizer(message, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "generated_ids = model.generate(input_ids, max_new_tokens=250, do_sample=True, repetition_penalty=1.3, temperature=0.8, top_p=0.75, top_k=40)\n",
    "response = tokenizer.decode(generated_ids[0][input_ids.shape[-1]:])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The following `model_kwargs` are not used by the model: ['token_type_ids'] (note: typos in the generate arguments will also show up in this list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39msdp_kernel(enable_flash\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, enable_math\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m      8\u001b[0m     \u001b[39m# outputs = model.generate(**inputs, max_length=50, num_return_sequences=1,do_sample=True, temperature=1.0, top_k=50, top_p=0.95,pad_token_id=tokenizer.eos_token_id,eos_token_id=49155)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Stop the timer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/chat/lib/python3.10/site-packages/transformers/generation/utils.py:1231\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1229\u001b[0m model_kwargs \u001b[39m=\u001b[39m generation_config\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# All unused kwargs must be model kwargs\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m generation_config\u001b[39m.\u001b[39mvalidate()\n\u001b[0;32m-> 1231\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_model_kwargs(model_kwargs\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m   1233\u001b[0m \u001b[39m# 2. Set generation parameters if not already defined\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m logits_processor \u001b[39m=\u001b[39m logits_processor \u001b[39mif\u001b[39;00m logits_processor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m LogitsProcessorList()\n",
      "File \u001b[0;32m~/miniconda3/envs/chat/lib/python3.10/site-packages/transformers/generation/utils.py:1109\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_kwargs\u001b[0;34m(self, model_kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         unused_model_args\u001b[39m.\u001b[39mappend(key)\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m unused_model_args:\n\u001b[0;32m-> 1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1110\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe following `model_kwargs` are not used by the model: \u001b[39m\u001b[39m{\u001b[39;00munused_model_args\u001b[39m}\u001b[39;00m\u001b[39m (note: typos in the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m generate arguments will also show up in this list)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1112\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The following `model_kwargs` are not used by the model: ['token_type_ids'] (note: typos in the generate arguments will also show up in this list)"
     ]
    }
   ],
   "source": [
    "prompt = '--查看怪物id'\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda:0')\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False):\n",
    "    outputs = model.generate(**inputs,)\n",
    "    # outputs = model.generate(**inputs, max_length=50, num_return_sequences=1,do_sample=True, temperature=1.0, top_k=50, top_p=0.95,pad_token_id=tokenizer.eos_token_id,eos_token_id=49155)\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "\n",
    "print(f'Generate token: {len(outputs[0])/elapsed_time:.2f} token/s')\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uework/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-21 05:16:15,906\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-09-21 05:16:16,286\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "prompts = [\n",
    "    '--查看怪物id',\n",
    "    \"--学习技能\",\n",
    "    \"--学习技能并查看怪物id\",\n",
    "    \"--学习技能并查看怪物id并打印出来\",\n",
    "]\n",
    "sampling_params = SamplingParams(temperature=0.2, top_p=0.95, top_k=4, max_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-21 07:16:23 llm_engine.py:72] Initializing an LLM engine with config: model='/home/uework/AiWeb/pwz/github/model/luacoder-3b/beta2/checkpoint-215', tokenizer='/home/uework/AiWeb/pwz/github/model/luacoder-3b/beta2/checkpoint-215', tokenizer_mode=auto, trust_remote_code=False, dtype=torch.bfloat16, download_dir=None, load_format=auto, tensor_parallel_size=1, seed=0)\n",
      "INFO 09-21 07:16:31 llm_engine.py:199] # GPU blocks: 105648, # CPU blocks: 14563\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(model=\"/home/uework/AiWeb/pwz/github/model/luacoder-3b/beta2/checkpoint-215\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RequestOutput(request_id=0, prompt='--查看怪物id', prompt_token_ids=[287, 24044, 3591, 122, 14615, 314], outputs=[CompletionOutput(index=0, text='\\nfunction isc_test_creature:get_id()\\n    local creature = edi.player:owner(module.player)\\n    local id = edi.creature:get_id(creature)\\n    LOGI(\"isc_test_creature get_id: \" .. id)\\nend\\n\\n--查看怪物名字\\nfunction isc_test_creature:get_name()\\n    local creature = edi.player:owner(module.player)\\n    local name = edi.creature:get_name(creature)\\n    LOGI(\"isc_test_creature get_name: \" ..', token_ids=[203, 1126, 438, 85, 81, 858, 81, 42717, 44, 371, 81, 314, 346, 284, 2196, 29472, 280, 2115, 91, 32, 3840, 44, 5632, 26, 1647, 32, 3840, 27, 284, 2196, 804, 280, 2115, 91, 32, 42717, 44, 371, 81, 314, 26, 42717, 27, 284, 5776, 59, 440, 25415, 81, 858, 81, 42717, 622, 81, 314, 44, 313, 4377, 804, 27, 203, 416, 203, 203, 287, 24044, 3591, 122, 14615, 38351, 203, 1126, 438, 85, 81, 858, 81, 42717, 44, 371, 81, 426, 346, 284, 2196, 29472, 280, 2115, 91, 32, 3840, 44, 5632, 26, 1647, 32, 3840, 27, 284, 2196, 636, 280, 2115, 91, 32, 42717, 44, 371, 81, 426, 26, 42717, 27, 284, 5776, 59, 440, 25415, 81, 858, 81, 42717, 622, 81, 426, 44, 313, 4377], cumulative_logprob=-0.9438739269971848, logprobs={}, finish_reason=length)], finished=True), RequestOutput(request_id=1, prompt='--学习技能', prompt_token_ids=[287, 22612, 17044, 4472], outputs=[CompletionOutput(index=0, text='\\nfunction isc_test_skill:study()\\n    local player = edi.player:owner(module.player)\\n    local skill_id = 1001\\n    local bRet = edi.skill:study(player, skill_id)\\n    LOGI(\"isc_test_skill study: \" .. tostring(bRet))\\nend\\n\\n--学习技能\\n---@param player userdata 玩家对象\\n---@param skill_id number 技能id\\n---@return boolean #是否学习成功\\nfunction isc_test_skill:study(player,skill_id)', token_ids=[203, 1126, 438, 85, 81, 858, 81, 10887, 44, 19900, 346, 284, 2196, 4362, 280, 2115, 91, 32, 3840, 44, 5632, 26, 1647, 32, 3840, 27, 284, 2196, 20838, 81, 314, 280, 225, 35, 34, 34, 35, 284, 2196, 323, 5925, 280, 2115, 91, 32, 10887, 44, 19900, 26, 3840, 30, 20838, 81, 314, 27, 284, 5776, 59, 440, 25415, 81, 858, 81, 10887, 14866, 44, 313, 4377, 372, 800, 26, 84, 5925, 490, 203, 416, 203, 203, 287, 22612, 17044, 4472, 203, 40685, 753, 4362, 1256, 605, 225, 39604, 11167, 9343, 203, 40685, 753, 20838, 81, 314, 1451, 29887, 227, 4472, 314, 203, 40685, 601, 1905, 588, 9260, 22612, 11798, 203, 1126, 438, 85, 81, 858, 81, 10887, 44, 19900, 26, 3840, 30, 10887, 81, 314, 27], cumulative_logprob=-3.465126246213913, logprobs={}, finish_reason=length)], finished=True), RequestOutput(request_id=2, prompt='--学习技能并查看怪物id', prompt_token_ids=[287, 22612, 17044, 4472, 8114, 24044, 3591, 122, 14615, 314], outputs=[CompletionOutput(index=0, text='\\nfunction isc_test_skill:study_skill()\\n    local player = edi.player:owner(module.player)\\n    local skill_id = 1001\\n    local bRet = edi.skill:study_skill(player, skill_id)\\n    LOGI(\"isc_test_skill study_skill: \" .. tostring(bRet))\\nend\\n\\n--学习技能并查看怪物id\\nfunction isc_test_skill:study_skill()\\n    local player = edi.player:owner(module.player)\\n    local skill_id =', token_ids=[203, 1126, 438, 85, 81, 858, 81, 10887, 44, 19900, 81, 10887, 346, 284, 2196, 4362, 280, 2115, 91, 32, 3840, 44, 5632, 26, 1647, 32, 3840, 27, 284, 2196, 20838, 81, 314, 280, 225, 35, 34, 34, 35, 284, 2196, 323, 5925, 280, 2115, 91, 32, 10887, 44, 19900, 81, 10887, 26, 3840, 30, 20838, 81, 314, 27, 284, 5776, 59, 440, 25415, 81, 858, 81, 10887, 14866, 81, 10887, 44, 313, 4377, 372, 800, 26, 84, 5925, 490, 203, 416, 203, 203, 287, 22612, 17044, 4472, 8114, 24044, 3591, 122, 14615, 314, 203, 1126, 438, 85, 81, 858, 81, 10887, 44, 19900, 81, 10887, 346, 284, 2196, 4362, 280, 2115, 91, 32, 3840, 44, 5632, 26, 1647, 32, 3840, 27, 284, 2196, 20838, 81, 314, 280], cumulative_logprob=-1.863354604691267, logprobs={}, finish_reason=length)], finished=True), RequestOutput(request_id=3, prompt='--学习技能并查看怪物id并打印出来', prompt_token_ids=[287, 22612, 17044, 4472, 8114, 24044, 3591, 122, 14615, 314, 8114, 34449, 36699], outputs=[CompletionOutput(index=0, text='\\nfunction isc_test_skill:study_skill()\\n    local player = edi.player:owner(module.player)\\n    local skill_id = 1001\\n    local bRet = edi.skill:study_skill(player, skill_id)\\n    LOGI(\"isc_test_skill study_skill: \" .. tostring(bRet))\\nend\\n\\n--学习技能并查看怪物id并打印出来\\nfunction isc_test_skill:study_skill()\\n    local player = edi.player:owner(module.player)\\n    local skill', token_ids=[203, 1126, 438, 85, 81, 858, 81, 10887, 44, 19900, 81, 10887, 346, 284, 2196, 4362, 280, 2115, 91, 32, 3840, 44, 5632, 26, 1647, 32, 3840, 27, 284, 2196, 20838, 81, 314, 280, 225, 35, 34, 34, 35, 284, 2196, 323, 5925, 280, 2115, 91, 32, 10887, 44, 19900, 81, 10887, 26, 3840, 30, 20838, 81, 314, 27, 284, 5776, 59, 440, 25415, 81, 858, 81, 10887, 14866, 81, 10887, 44, 313, 4377, 372, 800, 26, 84, 5925, 490, 203, 416, 203, 203, 287, 22612, 17044, 4472, 8114, 24044, 3591, 122, 14615, 314, 8114, 34449, 36699, 203, 1126, 438, 85, 81, 858, 81, 10887, 44, 19900, 81, 10887, 346, 284, 2196, 4362, 280, 2115, 91, 32, 3840, 44, 5632, 26, 1647, 32, 3840, 27, 284, 2196, 20838], cumulative_logprob=-1.2430781126022339, logprobs={}, finish_reason=length)], finished=True)]\n",
      "----------------------------------------\n",
      "Prompt: '--查看怪物id'\n",
      "Generated text:\n",
      "\n",
      "function isc_test_creature:get_id()\n",
      "    local creature = edi.player:owner(module.player)\n",
      "    local id = edi.creature:get_id(creature)\n",
      "    LOGI(\"isc_test_creature get_id: \" .. id)\n",
      "end\n",
      "\n",
      "--查看怪物名字\n",
      "function isc_test_creature:get_name()\n",
      "    local creature = edi.player:owner(module.player)\n",
      "    local name = edi.creature:get_name(creature)\n",
      "    LOGI(\"isc_test_creature get_name: \" ..\n",
      "----------------------------------------\n",
      "Prompt: '--学习技能'\n",
      "Generated text:\n",
      "\n",
      "function isc_test_skill:study()\n",
      "    local player = edi.player:owner(module.player)\n",
      "    local skill_id = 1001\n",
      "    local bRet = edi.skill:study(player, skill_id)\n",
      "    LOGI(\"isc_test_skill study: \" .. tostring(bRet))\n",
      "end\n",
      "\n",
      "--学习技能\n",
      "---@param player userdata 玩家对象\n",
      "---@param skill_id number 技能id\n",
      "---@return boolean #是否学习成功\n",
      "function isc_test_skill:study(player,skill_id)\n",
      "----------------------------------------\n",
      "Prompt: '--学习技能并查看怪物id'\n",
      "Generated text:\n",
      "\n",
      "function isc_test_skill:study_skill()\n",
      "    local player = edi.player:owner(module.player)\n",
      "    local skill_id = 1001\n",
      "    local bRet = edi.skill:study_skill(player, skill_id)\n",
      "    LOGI(\"isc_test_skill study_skill: \" .. tostring(bRet))\n",
      "end\n",
      "\n",
      "--学习技能并查看怪物id\n",
      "function isc_test_skill:study_skill()\n",
      "    local player = edi.player:owner(module.player)\n",
      "    local skill_id =\n",
      "----------------------------------------\n",
      "Prompt: '--学习技能并查看怪物id并打印出来'\n",
      "Generated text:\n",
      "\n",
      "function isc_test_skill:study_skill()\n",
      "    local player = edi.player:owner(module.player)\n",
      "    local skill_id = 1001\n",
      "    local bRet = edi.skill:study_skill(player, skill_id)\n",
      "    LOGI(\"isc_test_skill study_skill: \" .. tostring(bRet))\n",
      "end\n",
      "\n",
      "--学习技能并查看怪物id并打印出来\n",
      "function isc_test_skill:study_skill()\n",
      "    local player = edi.player:owner(module.player)\n",
      "    local skill\n",
      "Generate token: 256.13 token/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "outputs = llm.generate(prompts, sampling_params,use_tqdm=True)\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "token_num = 0\n",
    "print(outputs)\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    token_num += len(output.outputs[0].token_ids)\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print('----------------------------------------')\n",
    "    print(f\"Prompt: {prompt!r}\\nGenerated text:\")\n",
    "    print(generated_text)\n",
    "print(f'Generate token: {token_num/elapsed_time:.2f} token/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "    json.ipynb\n",
      "    lua.ipynb\n",
      "    utils.py\n",
      "    dialogue.ipynb\n",
      "    requirements.txt\n",
      "    README.md\n",
      "    scripts/\n",
      "        arguments.py\n",
      "        bpe_training.py\n",
      "        codeparrot_training.py\n",
      "        human_eval.py\n",
      "        initialize_model.py\n",
      "        minhash_deduplication.py\n",
      "        preprocessing.py\n",
      "        pretokenizing.py\n",
      "        validation_loss.py\n",
      "        preprocess.sh\n",
      "        tests/\n",
      "            test_deduplicate.py\n",
      "            __init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import os\n",
    "\n",
    "def list_files(startpath, skip_dirs=[]):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        # Remove the skipped directories from the list of directories to walk through\n",
    "        dirs[:] = [d for d in dirs if d not in skip_dirs]\n",
    "        \n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "\n",
    "list_files('/home/uework/AiWeb/pwz/github/luacoder/data', skip_dirs=[\"node_modules\", \"__pycache__\",\"wandb\",\"logs\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
