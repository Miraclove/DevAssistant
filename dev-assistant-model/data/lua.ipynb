{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [00:00<00:00, 8002.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "def get_files_from_directory(directory, ext='.lua'):\n",
    "    \"\"\"\n",
    "    遍历指定的目录，并返回所有.lua文件的完整路径。\n",
    "    \"\"\"\n",
    "    target_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(ext):\n",
    "                target_files.append(os.path.join(root, file))\n",
    "    return target_files\n",
    "\n",
    "lua_files = get_files_from_directory('/home/uework/AiWeb/pwz/github/data/lua', '.lua')\\\n",
    "\n",
    "df = pd.DataFrame(lua_files, columns=['file'])\n",
    "content = []\n",
    "for file in tqdm(lua_files):\n",
    "    with open(file, 'r') as f:\n",
    "        content.append(f.read())\n",
    "df['content'] = content\n",
    "df.head()\n",
    "\n",
    "df.to_csv('/home/uework/AiWeb/pwz/github/data/lua/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/uework/.cache/huggingface/datasets/csv/default-17402498c2acedab/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 360.65it/s]\n",
      "Loading cached processed dataset at /home/uework/.cache/huggingface/datasets/csv/default-17402498c2acedab/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-51e9ca12ce3c832c.arrow\n",
      "                                                                                            \r"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files='/home/uework/AiWeb/pwz/github/data/dataset/dialogue-lua/data_cn.csv')\n",
    "# add 'completion' as the features\n",
    "dataset = dataset.map(lambda x: {'completion': x['response']})\n",
    "dataset = dataset['train'].train_test_split(test_size=0.1)\n",
    "dataset.save_to_disk('/home/uework/AiWeb/pwz/github/data/dataset/dialogue-lua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#### load large dataset using dask df\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# File paths\n",
    "file_paths = '/home/uework/AiWeb/pwz/github/data/lua/starcoder-data/train-*.parquet'\n",
    "\n",
    "# Load data\n",
    "ddf = dd.read_parquet(file_paths)\n",
    "\n",
    "display(ddf.head())\n",
    "\n",
    "import pandas as pd\n",
    "ddf_code = dd.from_pandas(pd.read_csv('/home/uework/AiWeb/pwz/github/data/lua/shengqu/data.csv'),npartitions=10)\n",
    "ddf_code.head()\n",
    "\n",
    "ddf = dd.concat([ddf['content'], ddf_code['content']])\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from datasets import Dataset\n",
    "# Compute Dask DataFrame to get pandas DataFrame\n",
    "pdf = ddf.compute()\n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(pdf)\n",
    "\n",
    "dataset.save_to_disk('/home/uework/AiWeb/pwz/github/data/dataset/all-lua')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#### generate lua files from prompt and completion\n",
    "from utils import dialogue_to_lua\n",
    "# create dialogue\n",
    "dialogue_df = pd.read_csv('/home/uework/AiWeb/pwz/github/data/dataset/dialogue-lua/data_cn.csv')\n",
    "dialogue_to_lua(dialogue_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"/home/uework/AiWeb/pwz/github/data/dataset/openassistant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = dataset['train'].to_pandas()\n",
    "display(train_df.head()['text'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_from_disk\n",
    "from datasets import DatasetDict,Dataset\n",
    "from scripts.preprocessing import clean_dataset\n",
    "#################################################################\n",
    "#### generate dataset for luacoder\n",
    "\n",
    "dataset_folder = '/home/uework/AiWeb/pwz/github/data/dataset'\n",
    "dataset_name = 'test-lua'\n",
    "model_path = '/home/uework/AiWeb/pwz/github/model/starcoderbase-3b'\n",
    "files_directory = ['/home/uework/AiWeb/pwz/github/data/lua/api-doc-lua',\n",
    "                   '/home/uework/AiWeb/pwz/github/data/lua/shengqu',\n",
    "                   '/home/uework/AiWeb/pwz/github/data/lua/dialogue'\n",
    "                   ]\n",
    "generate_luacoder_dataset(dataset_folder,dataset_name,model_path,files_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notation: -- check if addon is enabled\n",
      "line code: if PA_SavedVars.Repair[activeProfile].enabled == true then\n",
      "start index: 123, end index: 180\n",
      "----\n",
      "notation: -- early check if there is something to repair\n",
      "line code: if GetRepairAllCost() > 0 then\n",
      "start index: 233, end index: 262\n",
      "----\n",
      "notation: -- check if equipped items shall be repaired\n",
      "line code: if PA_SavedVars.Repair[activeProfile].equipped then\n",
      "start index: 315, end index: 365\n",
      "----\n",
      "notation: -- check if backpack items shall be repaired\n",
      "line code: if PA_SavedVars.Repair[activeProfile].backpack then\n",
      "start index: 509, end index: 559\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "lua_code = '''\n",
    "function PAR.OnShopOpen()\n",
    "    local activeProfile = PA_SavedVars.General.activeProfile\n",
    "\n",
    "    -- check if addon is enabled\n",
    "\tif PA_SavedVars.Repair[activeProfile].enabled == true then\n",
    "\t\t-- early check if there is something to repair\n",
    "\t\tif GetRepairAllCost() > 0 then\n",
    "\t\t\t-- check if equipped items shall be repaired\n",
    "\t\t\tif PA_SavedVars.Repair[activeProfile].equipped then\n",
    "\t\t\t\tPAR.RepairItems(BAG_WORN, PA_SavedVars.Repair[activeProfile].equippedThreshold)\n",
    "\t\t\tend\n",
    "\t\t\t-- check if backpack items shall be repaired\n",
    "\t\t\tif PA_SavedVars.Repair[activeProfile].backpack then\n",
    "\t\t\t\tPAR.RepairItems(BAG_BACKPACK, PA_SavedVars.Repair[activeProfile].backpackThreshold)\n",
    "\t\t\tend\n",
    "\t\telse\n",
    "\t\t\tif (not PA_SavedVars.Repair[activeProfile].hideNoRepairMsg) then\n",
    "\t\t\t\tPAR.println(\"PAR_NoRepair\")\n",
    "\t\t\tend\n",
    "\t\tend\n",
    "\tend\n",
    "end\n",
    "'''\n",
    "\n",
    "matches = re.findall(r'(--[^\\n]*)\\n\\s*([^\\n]+)', lua_code)\n",
    "\n",
    "for match in matches:\n",
    "    notation, line_code = match\n",
    "    # Exclude lines of code that are comments\n",
    "    if not line_code.strip().startswith('--'):\n",
    "        start_idx = lua_code.index(line_code)\n",
    "        end_idx = start_idx + len(line_code) - 1\n",
    "        print(f\"notation: {notation.strip()}\")\n",
    "        print(f\"line code: {line_code.strip()}\")\n",
    "        print(f\"start index: {start_idx}, end index: {end_idx}\")\n",
    "        print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in /home/uework/AiWeb/pwz/github/data/lua/shengqu/logic/challenge_dragon/challenge_dragon_dup.lua on lines: 9\n",
      "Found in /home/uework/AiWeb/pwz/github/data/lua/shengqu/logic/manager/activity_mgr.lua on lines: 321\n",
      "Found in /home/uework/AiWeb/pwz/github/data/lua/shengqu/logic/personal_boss/personal_boss_dup.lua on lines: 11\n",
      "Found in /home/uework/AiWeb/pwz/github/data/lua/shengqu/logic/shabak/shabak_dup.lua on lines: 12\n",
      "Found in /home/uework/AiWeb/pwz/github/data/lua/shengqu/logic/swordSoul/swordSoulDup.lua on lines: 6, 8\n"
     ]
    }
   ],
   "source": [
    "from utils import search_files_for_substring\n",
    "directory = '/home/uework/AiWeb/pwz/github/data/lua/shengqu'\n",
    "substring = \"\"\"g_mir.common.activityMgr\"\"\"\n",
    "\n",
    "matches = search_files_for_substring(directory, substring)\n",
    "for filename, lines in matches:\n",
    "    print(f\"Found in {filename} on lines: {', '.join(map(str, lines))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uework/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 857/857 [00:01<00:00, 559.22it/s] \n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "# Get all Lua files in the directory\n",
    "directory_path = '/home/uework/AiWeb/pwz/github/data/lua/shengqu'  # Replace with your directory path\n",
    "results = find_all_samples(directory_path,mute=True)\n",
    "# print(json.dumps(results, indent=4))\n",
    "samples_to_lua_file(results,'output.lua')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
